{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear regression using pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7pgsmzbKiMb5coDtUus/y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamatul1214/Pytorch/blob/main/Linear_regression_using_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArL4gbNIjsTz",
        "outputId": "c98bf485-8e6e-4525-b513-a9da9b016213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar  7 18:08:18 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "## To check the GPU allocated\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## We have got Tesla K80 GPU"
      ],
      "metadata": {
        "id": "qkVOW6edkHMP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's create a sample dataset with 4 features and two labels.\n",
        "### Features- Region, Temperature, Rainfall, humidity\n",
        "### Label- Production of wheat, production of rice.\n",
        "## Here we have two labels in same data so we will have two different equations for each label. \n",
        "### y1 (Prod. of wheat)=w11*temp + w12*rainfall + w13*humidity + bias1\n",
        "### y2 (Prod. of Rice)=w21*temp + w22*rainfall + w23*humidity + bias2\n"
      ],
      "metadata": {
        "id": "sRhYRo2akxdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "xXMrflVukcG3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Let's create input data\n",
        "input=np.array([[32,55,77],\n",
        "                [82,15,37],\n",
        "                [72,74,90],\n",
        "                [34,56,90],\n",
        "                [67,32,45],\n",
        "                [91,90,45],], dtype='float32')        ## We can take float64 as well, but in order to save memory we are taking float32\n",
        "input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRzSfUV9keiL",
        "outputId": "b9416b95-9571-4cd9-f700-bd3d2a80c6bd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32., 55., 77.],\n",
              "       [82., 15., 37.],\n",
              "       [72., 74., 90.],\n",
              "       [34., 56., 90.],\n",
              "       [67., 32., 45.],\n",
              "       [91., 90., 45.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Let's create the target data of label\n",
        "target=np.array([[32,44],\n",
        "                 [78,61],\n",
        "                 [90,71],\n",
        "                 [74,32],\n",
        "                 [36,32],\n",
        "                 [22,69]], dtype='float32')\n",
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgH3IyKJmn8V",
        "outputId": "7047cc3a-f5a6-4391-98b8-ece2a9c72f3f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32., 44.],\n",
              "       [78., 61.],\n",
              "       [90., 71.],\n",
              "       [74., 32.],\n",
              "       [36., 32.],\n",
              "       [22., 69.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Now we need to convert input and target to tensors because we are going to work with pytorch. Pytorch and Tensorflow required tensors only because they also work on GPU\n",
        "\n",
        "input=torch.from_numpy(input)\n",
        "target=torch.from_numpy(target)\n",
        "\n",
        "print(input)\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Kzkpmu9nVQg",
        "outputId": "71a37016-504f-49c1-a9fb-3c0cec4ac12e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[32., 55., 77.],\n",
            "        [82., 15., 37.],\n",
            "        [72., 74., 90.],\n",
            "        [34., 56., 90.],\n",
            "        [67., 32., 45.],\n",
            "        [91., 90., 45.]])\n",
            "tensor([[32., 44.],\n",
            "        [78., 61.],\n",
            "        [90., 71.],\n",
            "        [74., 32.],\n",
            "        [36., 32.],\n",
            "        [22., 69.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PYTZzNAOoCXP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}